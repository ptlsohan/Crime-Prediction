{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 584 Machine Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Project: Crime Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import heapq\n",
    "import sys\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn import model_selection\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Adds a highCrime column to the input data set and prints the percentage of highCrime and low crime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AddHighCrimeFieldAndDumpStatistics(file_name):\n",
    "    try:\n",
    "        crime_data = pd.read_csv(file_name)\n",
    "        # Create a new field called highCrime which is true if the ViolentCrimesPerPop field is greater than 0.1\n",
    "        crime_data['highCrime'] = np.where(crime_data['ViolentCrimesPerPop'] >= 0.1, 'true', 'false')\n",
    "        high_crime_count = np.sum(crime_data['highCrime'] == 'true')\n",
    "        low_crime_count = np.sum(crime_data['highCrime'] == 'false')\n",
    "\n",
    "        high_crime_percentage = (high_crime_count / (high_crime_count + low_crime_count)) * 100\n",
    "        low_crime_percentage = (low_crime_count / (high_crime_count + low_crime_count)) * 100\n",
    "\n",
    "        print(\"HighCrime positive % is \", high_crime_percentage)\n",
    "        print(\"HighCrime negative % is \", low_crime_percentage)\n",
    "        \n",
    "    except:\n",
    "        print(\"unable to read \", file_name)\n",
    "        exit()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This class provides base functionality for processing and classifying crime data\n",
    "##### The classifiers are passed in by derived classes to the relevant methods of this class.\n",
    "##### The functionality provided includes\n",
    "##### 1.Running classification and dumping stats on the whole data set.\n",
    "##### 2.Running KFold validation on the data set.\n",
    "##### 3.cross_val_score() function to use the python libraries to score the classifier.\n",
    "##### 4.get_top_features() which provides a list of top features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CrimePredictorBase:\n",
    "    def __init__(self, file_name, clean):\n",
    "        self.file_name = file_name\n",
    "        self.clean = clean\n",
    "        self.read_crime_data()\n",
    "        self.process_crime_data()\n",
    "        self.classification = True\n",
    "        \n",
    "    def read_crime_data(self):\n",
    "        try:\n",
    "            self.input_crime_data = pd.read_csv(self.file_name)\n",
    "            print(\"Read: \", len(self.input_crime_data), \" records\")\n",
    "        except:\n",
    "            print(\"unable to read \", self.file_name)\n",
    "            exit()\n",
    "            \n",
    "    def process_crime_data(self):\n",
    "        # Delete the communityname column as it is not a predictor.\n",
    "        # Additionally the GaussianNB model does not support strings.\n",
    "        # We could have converted the column to an integer. However it is not a relevant\n",
    "        # column. We can safely ignore it.\n",
    "        del self.input_crime_data['communityname']\n",
    "        del self.input_crime_data['fold']\n",
    "        del self.input_crime_data['state']\n",
    "\n",
    "        self.actual_crime_class = np.where(self.input_crime_data['ViolentCrimesPerPop'] >= 0.1, 'true', 'false')\n",
    "        self.actual_crime = self.input_crime_data['ViolentCrimesPerPop']\n",
    "\n",
    "        self.high_crime_input = self.input_crime_data.loc[self.input_crime_data['ViolentCrimesPerPop'] >= 0.1]\n",
    "        self.low_crime_input = self.input_crime_data.loc[self.input_crime_data['ViolentCrimesPerPop'] < 0.1]\n",
    "        self.high_crime_output = self.high_crime_input[\"ViolentCrimesPerPop\"]\n",
    "        self.low_crime_output = self.low_crime_input[\"ViolentCrimesPerPop\"]\n",
    "        \n",
    "        del self.input_crime_data['ViolentCrimesPerPop']\n",
    "        del self.high_crime_input['ViolentCrimesPerPop']\n",
    "        del self.low_crime_input['ViolentCrimesPerPop']\n",
    "        \n",
    "        if (self.clean == False):\n",
    "            input_record_list = []\n",
    "            # The default imputer has trouble with strings other than NaN. To workaround\n",
    "            # this replace all ?s in the columns with NaNs\n",
    "            temp_crime_data = self.input_crime_data\n",
    "            for feature_index in temp_crime_data.dtypes.index:\n",
    "                temp_crime_data[feature_index]= temp_crime_data[feature_index].replace('?', 'NaN')\n",
    "\n",
    "            imputer = Imputer(strategy=\"mean\", axis=0)\n",
    "            temp_crime_data = imputer.fit_transform(temp_crime_data)\n",
    "            # After imputing the DataFrame loses the columns. We recreate the DataFrame with the columns.\n",
    "            # Clear the input data frame and then create a new instance from the imputed\n",
    "            # DataFrame. We make sure to retain the columns.\n",
    "            self.input_crime_data = self.input_crime_data[0:0]\n",
    "            self.input_crime_data = pd.DataFrame(temp_crime_data, columns=self.input_crime_data.columns)\n",
    "\n",
    "    # Returns the high crime statistics based on the array |crime_output| passed in.\n",
    "    def get_crime_rate_statistics(self):\n",
    "        high_crime_count = (self.actual_crime_class == 'true').sum()\n",
    "        low_crime_count = (self.actual_crime_class == 'false').sum()\n",
    "    \n",
    "        high_crime_percentage = (high_crime_count / (high_crime_count + low_crime_count)) * 100\n",
    "        low_crime_percentage = (low_crime_count / (high_crime_count + low_crime_count)) * 100\n",
    "\n",
    "        return high_crime_count, low_crime_count, high_crime_percentage, low_crime_percentage\n",
    "        \n",
    "    # Prints the high crime statistics based on the |crime_column|.\n",
    "    def dump_crime_statistics(self):\n",
    "        high_crime_count, low_crime_count, high_crime_percentage, low_crime_percentage = self.get_crime_rate_statistics()\n",
    "\n",
    "        assert(high_crime_count + low_crime_count == len(self.actual_crime))\n",
    "\n",
    "        print(\"High crime count:\", high_crime_count)\n",
    "        print(\"Low crime count:\", low_crime_count)\n",
    "\n",
    "        print(\"High crime percentage:\", high_crime_percentage)\n",
    "        print(\"Low crime percentage:\", low_crime_percentage)\n",
    "        \n",
    "    # Runs the |classifier| on the DataFrame |input_crime_data|. The desired output is\n",
    "    # |actual_crime|. Returns the predicted crime.\n",
    "    def run_classifier_on_whole_dataset(self, classifier):\n",
    "        if (self.classification == True):\n",
    "            labelencoder_Y= LabelEncoder()\n",
    "            encoded_output = labelencoder_Y.fit_transform(self.actual_crime_class)\n",
    "        else:\n",
    "            encoded_output = self.actual_crime\n",
    "        \n",
    "        classifier.fit(self.input_crime_data, encoded_output)\n",
    "        predicted_crime = classifier.predict(self.input_crime_data)\n",
    "        self.dump_statistics(encoded_output, predicted_crime)\n",
    "        return predicted_crime\n",
    "    \n",
    "    def run_classifier_with_train_test_split(self, classifier, size):\n",
    "        if (self.classification == True):\n",
    "            labelencoder_Y= LabelEncoder()\n",
    "            encoded_output = labelencoder_Y.fit_transform(self.actual_crime_class)\n",
    "        else:\n",
    "            encoded_output = self.actual_crime\n",
    "        \n",
    "        X_train, X_test, Y_train, Y_test= model_selection.train_test_split(self.input_crime_data, encoded_output, test_size=size, random_state=0)\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        predicted = classifier.predict(X_test)\n",
    "        self.dump_statistics(Y_test, predicted)\n",
    "    \n",
    "    # Runs the |classifier| with cross validation on the DataFrame |input_crime_data|.\n",
    "    # The desired output is |actual_crime|. Returns the predicted crime.\n",
    "    def run_classifier_with_cross_validation(self, classifier, folds,):\n",
    "        print(\"Running classifier with cross validation for \", folds, \" folds\")\n",
    "\n",
    "        if (self.classification == True):\n",
    "            labelencoder_Y= LabelEncoder()\n",
    "            encoded_output = labelencoder_Y.fit_transform(self.actual_crime_class)\n",
    "        else:\n",
    "            encoded_output = self.actual_crime\n",
    "        \n",
    "        kf = KFold(len(self.input_crime_data), folds, shuffle=True, random_state=None)\n",
    "    \n",
    "        for train_index, test_index in kf:\n",
    "            test_data_frame = pd.DataFrame(columns = self.input_crime_data.columns)\n",
    "            input_record_list = []\n",
    "            crime_rate = []\n",
    "            for next_training_index in train_index:\n",
    "                input_record_list.append(self.input_crime_data.ix[next_training_index])\n",
    "                crime_rate.append(encoded_output[next_training_index])\n",
    "            training_data_frame = pd.DataFrame(input_record_list)\n",
    "            \n",
    "            classifier.fit(training_data_frame, crime_rate)\n",
    "\n",
    "            input_record_list = []\n",
    "            crime_rate = []\n",
    "            for next_test_index in test_index:\n",
    "                input_record_list.append(self.input_crime_data.ix[next_test_index])\n",
    "                crime_rate.append(self.actual_crime[next_test_index])\n",
    "            test_data_frame = pd.DataFrame(input_record_list)\n",
    "            predicted_crime = classifier.predict(test_data_frame)\n",
    "            #self.dump_statistics(encoded_output, predicted_crime)\n",
    "    \n",
    "    def cross_val_score(self, classifier, folds):\n",
    "        print(\"Cross Validation scores for \", folds, \"folds\")\n",
    "        if (self.classification == True):\n",
    "            actual_crime = np.where(self.actual_crime_class == \"true\", 1, 0)\n",
    "            precision = np.mean(model_selection.cross_val_score(classifier, self.input_crime_data, actual_crime, cv=folds, scoring='precision'))\n",
    "            accuracy = np.mean(model_selection.cross_val_score(classifier, self.input_crime_data, actual_crime, cv=folds, scoring='accuracy'))\n",
    "            recall = np.mean(model_selection.cross_val_score(classifier, self.input_crime_data, actual_crime, cv=folds, scoring='recall'))\n",
    "\n",
    "            print(\"Accuracy: \", accuracy)\n",
    "            print(\"Precision: \", precision)\n",
    "            print(\"Recall: \", recall)\n",
    "            return accuracy, precision, recall\n",
    "        else:\n",
    "            actual_crime = self.actual_crime\n",
    "            mean_square_error = np.mean(model_selection.cross_val_score(classifier, self.input_crime_data, actual_crime, cv=folds, scoring='neg_mean_squared_error'))\n",
    "            print(\"MSE is \", abs(mean_square_error))\n",
    "            return abs(mean_square_error)\n",
    "\n",
    "    # Gets the top features used for prediction. The |feature_count| is the count of\n",
    "    # features desired. The |input_crime_data| is the input DataFrame. The |actual_crime|\n",
    "    # is the desired output.\n",
    "    def get_top_features(self, feature_count, feature_scores, feature_ranker):\n",
    "        coefs_with_feature_names = sorted(zip(feature_scores, self.input_crime_data.dtypes.index))\n",
    "    \n",
    "        # We use a max heap to determine the top features. The key is the absolute value of the feature weight.\n",
    "        predictive_feature_heap = []\n",
    "        for coefficient, feature_name in coefs_with_feature_names:\n",
    "            heapq.heappush(predictive_feature_heap, feature_ranker(coefficient, feature_name))\n",
    "\n",
    "        # The top features are returned in a list.\n",
    "        top_feature_list = []\n",
    "        count_features = 0\n",
    "        for next_feature in predictive_feature_heap:\n",
    "            feature = heapq.heappop(predictive_feature_heap)\n",
    "            top_feature_list.append(feature.feature_name)\n",
    "            count_features = count_features + 1\n",
    "            if (count_features == feature_count):\n",
    "                break\n",
    "    \n",
    "        return top_feature_list\n",
    "    \n",
    "    # Dumps the statistics for the predicted crime vs actual crime.        \n",
    "    def dump_statistics(self, actual_crime, predicted_crime):\n",
    "        if (self.classification == False):\n",
    "            print(\"MSE is\", metrics.mean_squared_error(actual_crime, predicted_crime))\n",
    "            return\n",
    "        cm = confusion_matrix(actual_crime, predicted_crime)\n",
    "        print(\"Confusion matrix\", cm)\n",
    "        accuracy = accuracy_score(actual_crime, predicted_crime)\n",
    "        print(\"Accuracy\", accuracy)\n",
    "        prec = precision_score(actual_crime, predicted_crime)\n",
    "        print(\"Precision\", prec)\n",
    "        rec= recall_score(actual_crime, predicted_crime)\n",
    "        print(\"Recall\", rec)\n",
    "    \n",
    "    def set_poly(self, use_poly, poly_degree):\n",
    "        self.use_poly = use_poly\n",
    "        self.degree = poly_degree\n",
    "        if (self.use_poly):\n",
    "            self.poly = PolynomialFeatures(degree=poly_degree)\n",
    "            self.input_crime_data = self.poly.fit_transform(self.input_crime_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a Max heap to get the top 10 most predictive features.\n",
    "We use a max heap to get the top features for the LinearSVC classifier. The key is the absolute value of the feature weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MaxHeapFeatures(object):\n",
    "        def __init__(self, feature_weight, feature_name):\n",
    "            self.absolute_feature_weight = abs(feature_weight)\n",
    "            self.feature_name = feature_name\n",
    "    \n",
    "        def __lt__(self, other):\n",
    "            return self.absolute_feature_weight > other.absolute_feature_weight\n",
    "\n",
    "        def __eq__(self, other):\n",
    "            return self.absolute_feature_weight == other.absolute_feature_weight\n",
    "\n",
    "        def __str__(self):\n",
    "            return str(self.absolute_feature_weight)\n",
    "    \n",
    "        def feature_name(self):\n",
    "            return self.feature_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provides DecisionTree classification functionality.                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecisionTreeCrimePredictor(CrimePredictorBase):\n",
    "    def __init__(self, file_name, clean):\n",
    "        CrimePredictorBase.__init__(self, file_name, clean)\n",
    "        self.classifier = DecisionTreeClassifier(criterion= 'entropy', random_state=0)\n",
    "        \n",
    "    def cross_val_score(self, folds):\n",
    "        print(\"DecisionTree crossvalidation score for \", folds, \" folds is\")\n",
    "        CrimePredictorBase.cross_val_score(self, self.classifier, folds)\n",
    "        \n",
    "    def run_classifier_on_whole_dataset(self):\n",
    "        print(\"Running DecisionTreeClassifier on whole data set\")\n",
    "        return CrimePredictorBase.run_classifier_on_whole_dataset(self, self.classifier)\n",
    "\n",
    "    def run_classifier_with_train_test_split(self, size):\n",
    "        print(\"Running DecisionTreeClassifier with train test split: \", size)\n",
    "        return CrimePredictorBase.run_classifier_with_train_test_split(self, self.classifier, size)\n",
    "        \n",
    "    # Gets the top features used for prediction. The |feature_count| is the count of\n",
    "    # features desired. The |input_crime_data| is the input DataFrame. The |actual_crime|\n",
    "    # is the desired output.\n",
    "    def dump_top_features(self, feature_count):\n",
    "        self.classifier.fit(self.input_crime_data, self.actual_crime_class)\n",
    "        top_feature_list = CrimePredictorBase.get_top_features(self, feature_count, self.classifier.feature_importances_, MaxHeapFeatures)\n",
    "        print(\"\\n\\nTop feature list for DecisionTreeClassifier is\")\n",
    "    \n",
    "        for feature in top_feature_list:\n",
    "            print(feature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1 a. Create a new field “highCrime” which is true if the crime rate per capita (ViolentCrimesPerPop) is greater than 0.1, and false otherwise. What are the percentage of positive and negative instances in the dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ****** High crime statistics test ******\n",
      "\n",
      "HighCrime positive % is  65.9307576518\n",
      "HighCrime negative % is  34.0692423482\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n ****** High crime statistics test ******\\n\")\n",
    "AddHighCrimeFieldAndDumpStatistics(\"communities-crime-clean.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. DecisionTreeClassifier to learn a decision tree to predict highCrime on the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** DecisionTreeClassifier tests ******\n",
      "\n",
      "Read:  1993  records\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n****** DecisionTreeClassifier tests ******\\n\")\n",
    "\n",
    "decision_tree_crime_predictor = DecisionTreeCrimePredictor(\"communities-crime-clean.csv\", True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1b i. What are the training accuracy, precision, and recall for this tree? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DecisionTreeClassifier on whole data set\n",
      "Confusion matrix [[ 679    0]\n",
      " [   0 1314]]\n",
      "Accuracy 1.0\n",
      "Precision 1.0\n",
      "Recall 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_crime_predictor.run_classifier_on_whole_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classification on Train-Test split with 25% for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DecisionTreeClassifier with train test split:  0.25\n",
      "Confusion matrix [[115  65]\n",
      " [ 46 273]]\n",
      "Accuracy 0.77755511022\n",
      "Precision 0.807692307692\n",
      "Recall 0.855799373041\n"
     ]
    }
   ],
   "source": [
    "decision_tree_crime_predictor.run_classifier_with_train_test_split(0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Top feature list for DecisionTreeClassifier is\n",
      "PctKids2Par\n",
      "racePctWhite\n",
      "racePctHisp\n",
      "pctWInvInc\n",
      "HousVacant\n",
      "pctWRetire\n",
      "householdsize\n",
      "agePct65up\n",
      "HispPerCap\n",
      "AsianPerCap\n"
     ]
    }
   ],
   "source": [
    "decision_tree_crime_predictor.dump_top_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1b ii. What are the main features used for classification?. Can you explain why they make sense or not.\n",
    "Answer. The top 10 features used for classification are as below in order of importance.\n",
    "1. PctKids2Par\n",
    "2. racePctWhite\n",
    "3. racePctHisp\n",
    "4. pctWInvInc\n",
    "5. HousVacant\n",
    "6. pctWRetire\n",
    "7. householdsize\n",
    "8. agePct65up\n",
    "9. HispPerCap\n",
    "10. AsianPerCap\n",
    "\n",
    "They make sense due to the following reasons.\n",
    "1. Crime rate is generally high in poorer neighborhoods. Here education is generally low,\n",
    "   unemployment is high, etc. Sadly these neighborhoods are mostly black neigborhoods, people    of color, etc. Hence it makes sense that racePctHisp, HispPerCap, PctKids2Par are in the      top 10 features. \n",
    "\n",
    "   PctKids2Par\n",
    "   Families with more children struggle to provide for the kids, leading to crime.\n",
    "   \n",
    "   racePctHisp,HispPerCap\n",
    "   Hispanic neighborhoods associate with poorer neighborhoods with people of color\n",
    "   Sadly associated with high crime.\n",
    "\n",
    "2. White neighborhoods are generally affluent neighborhoods. Hence low crime. Thus makes sense\n",
    "   that racePctWhite is in the top 10 features.\n",
    "\n",
    "3. AsianPerCap\n",
    "   Asians are generally educated immigrants. While there are always exceptions, in the general\n",
    "   case it makes sense that neighborhoods with more asians are low in crime.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Cross validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1c i. What are the 10-fold cross-validation accuracy, precision, and recall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree crossvalidation score for  10  folds is\n",
      "Cross Validation scores for  10 folds\n",
      "Accuracy:  0.754604360185\n",
      "Precision:  0.817083652408\n",
      "Recall:  0.812618551932\n"
     ]
    }
   ],
   "source": [
    "decision_tree_crime_predictor.cross_val_score(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1c ii: Why are they different from the results in the previous test?\n",
    "Answer: The first test which uses the same dataset for training and testing reports results as Accuracy = 1.0, Precision = 1.0, Recall = 1.0. The 100% success results are expected because  we are training and testing on the same data, which is cheating. The cross validation tests randomly split the dataset into training and test sets over a number of folds. As a result it generally makes sense that the results you get from cross validation are a better predictor of the reliability of the classifier. Makes sense that the cross validation test accuracy/precision/recall are lower than training and testing on the same dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provides GaussianNB classification functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GaussianNBCrimePredictor(CrimePredictorBase):\n",
    "    def __init__(self, file_name, clean):\n",
    "        CrimePredictorBase.__init__(self, file_name, clean)\n",
    "        self.classifier = GaussianNB()\n",
    "\n",
    "    def run_classifier_on_whole_dataset(self):\n",
    "        print(\"Running GaussianNB on whole data set\")\n",
    "        return CrimePredictorBase.run_classifier_on_whole_dataset(self, self.classifier)\n",
    "    \n",
    "    def run_classifier_with_cross_validation(self, folds):\n",
    "        return CrimePredictorBase.run_classifier_with_cross_validation(self, self.classifier, folds)\n",
    "    \n",
    "    def cross_val_score(self, folds):\n",
    "        print(\"GaussianNB crossvalidation score for \", folds, \" folds is\")\n",
    "        CrimePredictorBase.cross_val_score(self, self.classifier, folds)\n",
    "        \n",
    "    # We use a Max heap to get the top 10 most predictive features.\n",
    "    class MaxHeapFeatures(object):\n",
    "        def __init__(self, absolute_mean_difference, feature_name):\n",
    "            self.absolute_mean_difference = absolute_mean_difference\n",
    "            self.feature_name = feature_name\n",
    "    \n",
    "        def __lt__(self, other):\n",
    "            return self.absolute_mean_difference > other.absolute_mean_difference\n",
    "\n",
    "        def __eq__(self, other):\n",
    "            return self.absolute_mean_difference == other.absolute_mean_difference\n",
    "\n",
    "        def __str__(self):\n",
    "            return str(self.absolute_mean_difference)\n",
    "    \n",
    "        def feature_name(self):\n",
    "            return self.feature_name\n",
    "        \n",
    "    def dump_top_features(self, feature_count):\n",
    "        print(\"\\n\\nTop feature list for GaussianNB is\")\n",
    "        \n",
    "        # We use a max heap to determine the top features. The key is the diff between positive and negative\n",
    "        # feature mean for the desired classes.\n",
    "        predictive_feature_heap = []\n",
    "        for feature_index in self.input_crime_data.dtypes.index:\n",
    "            mean_positive_crime_for_feature = np.sum(self.high_crime_input[feature_index]) / len(self.high_crime_input[feature_index])\n",
    "            mean_negative_crime_for_feature = np.sum(self.low_crime_input[feature_index]) / len(self.low_crime_input[feature_index])\n",
    "            diff = abs(mean_positive_crime_for_feature - mean_negative_crime_for_feature)\n",
    "            heapq.heappush(predictive_feature_heap, self.MaxHeapFeatures(abs(diff), feature_index))\n",
    "\n",
    "        # The top features are returned in a list.\n",
    "        top_feature_list = []\n",
    "        count_features = 0\n",
    "        for next_feature in predictive_feature_heap:\n",
    "            feature = heapq.heappop(predictive_feature_heap)\n",
    "            top_feature_list.append(feature.feature_name)\n",
    "            count_features = count_features + 1\n",
    "            if (count_features == feature_count):\n",
    "                break\n",
    "            \n",
    "        for feature in top_feature_list:\n",
    "            print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** GaussianNB tests ******\n",
      "\n",
      "Read:  1993  records\n",
      "Running GaussianNB on whole data set\n",
      "Confusion matrix [[619  60]\n",
      " [394 920]]\n",
      "Accuracy 0.772202709483\n",
      "Precision 0.938775510204\n",
      "Recall 0.700152207002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n****** GaussianNB tests ******\\n\")\n",
    "\n",
    "gaussian_crime_predictor = GaussianNBCrimePredictor(\"communities-crime-clean.csv\", True)\n",
    "gaussian_crime_predictor.run_classifier_on_whole_dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2a i. What is the 10-fold cross-validation accuracy, precision, and recall for this method?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB crossvalidation score for  10  folds is\n",
      "Cross Validation scores for  10 folds\n",
      "Accuracy:  0.761584386579\n",
      "Precision:  0.925010462289\n",
      "Recall:  0.699178811011\n"
     ]
    }
   ],
   "source": [
    "gaussian_crime_predictor.cross_val_score(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10 most predictive features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Top feature list for GaussianNB is\n",
      "PctKids2Par\n",
      "racePctWhite\n",
      "PctFam2Par\n",
      "PctYoungKids2Par\n",
      "PctIlleg\n",
      "PctHousNoPhone\n",
      "TotalPctDiv\n",
      "pctWPubAsst\n",
      "racepctblack\n",
      "FemalePctDiv\n"
     ]
    }
   ],
   "source": [
    "gaussian_crime_predictor.dump_top_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2a i. What are the 10 most predictive features? This can be measured by the normalized absolute difference of means for the feature between the two classes:\n",
    "Answer: The 10 most predictive features for Gaussian Naive Bayes are as below:\n",
    "1. PctKids2Par\n",
    "2. racePctWhite\n",
    "3. PctFam2Par\n",
    "4. PctYoungKids2Par\n",
    "5. PctIlleg\n",
    "6. PctHousNoPhone\n",
    "7. TotalPctDiv\n",
    "8. pctWPubAsst\n",
    "9. racepctblack\n",
    "10. FemalePctDiv\n",
    "\n",
    "Measuring this as the difference between the means of the features between high crime and low crime makes sense, as it helps measure how the feature affects crime. For e.g. the top 2 features are PctKids2Par and racePctWhite. We generally know that white neighborhoods are richer. Hence they are generally low crime. Hence the difference between the percentage of white people for high and low crime makes a lot of sense. If the percentage of high people is higher, low crime and vice versa. We can argue on similar lines for  PctKids2Par (Families with more kids stuggle to provide for them. Hence high crime, etc.) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2a iii: How do these results compare with Decision trees above?\n",
    "The top 2 features PctKids2PerPar and racePctWhite are common for Decision trees and Gaussian Naive Bayes.\n",
    "However Gaussian Naive Bayes has these features in the top 6 \n",
    "\n",
    "PctFam2Par\n",
    "Neighborhoods where more kids have 2 parents could classify as low crime. Because 2 parents\n",
    "could mean more income to the family. Hence kids are better cared for.\n",
    "\n",
    "PctYoungKids2Par\n",
    "Young kids under 2 and 4 are not associated with crime. Makes sense if this percentage is higher than low crime.\n",
    "\n",
    "PctIlleg\n",
    "Illegal immigrants are associated with poorer neighborhoods. Hence makes sense that there is more crime here.\n",
    "\n",
    "PctHousNoPhone\n",
    "No phone equals poorer families. Makes sense that more crime here.\n",
    "\n",
    "All in all Gaussian Naive Bayes appears to have features which better predict crime at least for this dataset\n",
    "in the top 10.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. LinearSVC to learn a linear Support Vector Machine model to predict highCrime.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provides SVM classification functionality.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SVMCrimePredictor(CrimePredictorBase):\n",
    "    def __init__(self, file_name, svm_kernel, classification, clean):\n",
    "        CrimePredictorBase.__init__(self, file_name, clean)\n",
    "        self.kernel = svm_kernel\n",
    "        self.classification = classification\n",
    "        if (self.classification == True):\n",
    "            if (svm_kernel == 'linear'):\n",
    "                self.classifier = svm.LinearSVC()\n",
    "            else:\n",
    "                self.classifier = svm.SVC(kernel=svm_kernel)\n",
    "        else:\n",
    "            self.classifier = svm.SVR(kernel=svm_kernel)\n",
    "\n",
    "    def run_classifier_on_whole_dataset(self):\n",
    "        if (self.kernel == \"linear\"):\n",
    "            print(\"Running LinearSVC on whole data set\")\n",
    "        else:\n",
    "            print(\"Running \", self.kernel, \"on whole data set\")\n",
    "        return CrimePredictorBase.run_classifier_on_whole_dataset(self, self.classifier)\n",
    "    \n",
    "    def run_classifier_with_cross_validation(self, folds):\n",
    "        return CrimePredictorBase.run_classifier_with_cross_validation(self, self.classifier, folds)\n",
    "    \n",
    "    def cross_val_score(self, folds):\n",
    "        if (self.kernel == \"linear\"):\n",
    "            print(\"LinearSVC crossvalidation score for \", folds, \" folds is\")\n",
    "        else:\n",
    "            print(\"SVM kernel \", self.kernel, \" crossvalidation score for \", folds, \" folds is\")\n",
    "        CrimePredictorBase.cross_val_score(self, self.classifier, folds)\n",
    "        \n",
    "    # We use a Max heap to get the top 10 most predictive features.\n",
    "    # We use a max heap to get the top features for the LinearSVC classifier. The key is the \n",
    "    # absolute value of the feature weight.\n",
    "    class MaxHeapFeatures(object):\n",
    "        def __init__(self, feature_weight, feature_name):\n",
    "            self.absolute_feature_weight = abs(feature_weight)\n",
    "            self.feature_name = feature_name\n",
    "    \n",
    "        def __lt__(self, other):\n",
    "            return self.absolute_feature_weight > other.absolute_feature_weight\n",
    "\n",
    "        def __eq__(self, other):\n",
    "            return self.absolute_feature_weight == other.absolute_feature_weight\n",
    "\n",
    "        def __str__(self):\n",
    "            return str(self.absolute_feature_weight)\n",
    "    \n",
    "        def feature_name(self):\n",
    "            return self.feature_name\n",
    "        \n",
    "    def dump_top_features(self, feature_count):\n",
    "        if (self.kernel == \"linear\"):\n",
    "            self.classifier.fit(self.input_crime_data, self.actual_crime_class)\n",
    "            top_feature_list = CrimePredictorBase.get_top_features(self, feature_count, self.classifier.coef_[0], self.MaxHeapFeatures)\n",
    "            print(\"\\n\\nTop feature list for kernel \", self.kernel, \" is\")\n",
    "    \n",
    "            for feature in top_feature_list:\n",
    "                print(feature)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** LinearSVC tests ******\n",
      "\n",
      "Read:  1993  records\n",
      "High crime count: 1314\n",
      "Low crime count: 679\n",
      "High crime percentage: 65.9307576518\n",
      "Low crime percentage: 34.0692423482\n",
      "Running LinearSVC on whole data set\n",
      "Confusion matrix [[ 539  140]\n",
      " [ 151 1163]]\n",
      "Accuracy 0.853988961365\n",
      "Precision 0.892555640829\n",
      "Recall 0.885083713851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n****** LinearSVC tests ******\\n\")\n",
    "\n",
    "linear_svc_crime_predictor = SVMCrimePredictor(\"communities-crime-clean.csv\", \"linear\", True, True)\n",
    "linear_svc_crime_predictor.dump_crime_statistics()\n",
    "linear_svc_crime_predictor.run_classifier_on_whole_dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2b i. What is the 10-fold cross-validation accuracy, precision, and recall for this method?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC crossvalidation score for  10  folds is\n",
      "Cross Validation scores for  10 folds\n",
      "Accuracy:  0.796212603421\n",
      "Precision:  0.854739828064\n",
      "Recall:  0.84141221374\n"
     ]
    }
   ],
   "source": [
    "linear_svc_crime_predictor.cross_val_score(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2b ii.What are the 10 most predictive features? This can be measured by the absolute feature weights in the model. Why do these make sense (or not)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Top feature list for kernel  linear  is\n",
      "pctWInvInc\n",
      "PctKids2Par\n",
      "RentHighQ\n",
      "PersPerOccupHous\n",
      "MalePctDivorce\n",
      "racePctWhite\n",
      "agePct65up\n",
      "HousVacant\n",
      "racePctHisp\n",
      "MedRent\n"
     ]
    }
   ],
   "source": [
    "\n",
    "linear_svc_crime_predictor.dump_top_features(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The top 10 predictive features for LinearSVC are as below:\n",
    "1. pctWInvInc\n",
    "2. PctKids2Par\n",
    "3. RentHighQ\n",
    "4. PersPerOccupHous\n",
    "5. MalePctDivorce\n",
    "6. racePctWhite\n",
    "7. agePct65up\n",
    "8. HousVacant\n",
    "9. racePctHisp\n",
    "10. MedRent\n",
    "\n",
    "Linear support vector machine attempt to find a linear boundary between the two classes. The regression line\n",
    "which separates the two classes is determined by the values of the weights(coefficients) associated with the features.\n",
    "Higher the weight the better predictor the feature is. This method of associating the feature importance\n",
    "based on the feature weight (coefficient) makes perfect sense.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question  2b iii. How do these results compare with your results from decision trees, above?\n",
    "Answer: pctWInvInc, PctKids2Par, racePctWhite, racePctHisp, agePct65up are common in both\n",
    "classifiers. The ordering is different though. For e.g. PctKids2Par is the top feature in\n",
    "Decision tree and is the second most important feature in LinearSVC and so on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. LinearRegression to learn a linear model directly predicting the crime rate per capita (ViolentCrimesPerPop).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provides LinearRegression prediction.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LinearRegressionCrimePredictor(CrimePredictorBase):\n",
    "    def __init__(self, file_name, use_poly, degree, clean):\n",
    "        CrimePredictorBase.__init__(self, file_name, clean)\n",
    "        CrimePredictorBase.set_poly(self, use_poly, degree)\n",
    "        self.classification = False\n",
    "        self.classifier = LinearRegression()\n",
    "        \n",
    "    def cross_val_score(self, folds):\n",
    "        print(\"LinearRegression crossvalidation score for \", folds, \" folds is\")\n",
    "        CrimePredictorBase.cross_val_score(self, self.classifier, folds)\n",
    "        \n",
    "    def run_classifier_on_whole_dataset(self):\n",
    "        print(\"Running LinearRegresion on whole data set\")\n",
    "        return CrimePredictorBase.run_classifier_on_whole_dataset(self, self.classifier)\n",
    "        \n",
    "    # Gets the top features used for prediction. The |feature_count| is the count of\n",
    "    # features desired. The |input_crime_data| is the input DataFrame. The |actual_crime|\n",
    "    # is the desired output.\n",
    "    def dump_top_features(self, feature_count):\n",
    "        self.classifier.fit(self.high_crime_input, self.high_crime_output)\n",
    "        top_feature_list = CrimePredictorBase.get_top_features(self, feature_count, self.classifier.coef_, SVMCrimePredictor.MaxHeapFeatures)\n",
    "        print(\"\\n\\nTop feature list for LinearRegression high crime rate is\")\n",
    "    \n",
    "        for feature in top_feature_list:\n",
    "            print(feature)\n",
    "\n",
    "        self.classifier.fit(self.low_crime_input, self.low_crime_output)\n",
    "        top_feature_list = CrimePredictorBase.get_top_features(self, feature_count, self.classifier.coef_, SVMCrimePredictor.MaxHeapFeatures)\n",
    "        print(\"\\n\\nTop feature list for LinearRegression low crime rate is\")\n",
    "    \n",
    "        for feature in top_feature_list:\n",
    "            print(feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** LinearRegression tests ******\n",
      "\n",
      "Read:  1993  records\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n****** LinearRegression tests ******\\n\")\n",
    "\n",
    "linear_regression_crime_predictor = LinearRegressionCrimePredictor(\"communities-crime-clean.csv\", False, 0, True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3a i.Using 10-fold cross-validation, what is the estimated mean-squared-error (MSE) of the model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression crossvalidation score for  10  folds is\n",
      "Cross Validation scores for  10 folds\n",
      "MSE is  0.0200939693044\n"
     ]
    }
   ],
   "source": [
    "linear_regression_crime_predictor.cross_val_score(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3a ii.What is the MSE on the training set (train on all the data then test on it all)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LinearRegresion on whole data set\n",
      "MSE is 0.0165167748803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.20829089,  0.3241512 ,  0.5673497 , ...,  0.08907789,\n",
       "        0.15564742,  0.17669898])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression_crime_predictor.run_classifier_on_whole_dataset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3a iii.What features are most predictive of a high crime rate? A low crime rate?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Top feature list for LinearRegression high crime rate is\n",
      "PctPersOwnOccup\n",
      "PctHousOwnOcc\n",
      "MedRent\n",
      "PersPerOccupHous\n",
      "RentLowQ\n",
      "PctRecImmig8\n",
      "PersPerRentOccHous\n",
      "OwnOccLowQuart\n",
      "population\n",
      "TotalPctDiv\n",
      "\n",
      "\n",
      "Top feature list for LinearRegression low crime rate is\n",
      "population\n",
      "TotalPctDiv\n",
      "numbUrban\n",
      "PersPerFam\n",
      "FemalePctDiv\n",
      "MalePctDivorce\n",
      "PctLargHouseFam\n",
      "racePctWhite\n",
      "NumImmig\n",
      "PctLargHouseOccup\n"
     ]
    }
   ],
   "source": [
    "linear_regression_crime_predictor.dump_top_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provides RidgeRegression prediction.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RidgeRegressionCrimePredictor(CrimePredictorBase):\n",
    "    def __init__(self, file_name, alphas_array, clean):\n",
    "        CrimePredictorBase.__init__(self, file_name, clean)\n",
    "        self.classification = False\n",
    "        self.alphas = alphas_array\n",
    "        self.classifier = RidgeCV(alphas=alphas_array)\n",
    "        \n",
    "    def cross_val_score(self, folds):\n",
    "        print(\"RidgeCV crossvalidation score for \", folds, \" folds is\")\n",
    "        CrimePredictorBase.cross_val_score(self, self.classifier, folds)\n",
    "        \n",
    "    def get_best_alpha(self):\n",
    "        self.classifier.fit(self.input_crime_data, self.actual_crime)\n",
    "        print(\"Best Alpha is \", self.classifier.alpha_)\n",
    "        \n",
    "    def run_classifier_on_whole_dataset(self):\n",
    "        print(\"Running RidgeCV on whole data set\")\n",
    "        return CrimePredictorBase.run_classifier_on_whole_dataset(self, self.classifier)\n",
    "        \n",
    "    # Gets the top features used for prediction. The |feature_count| is the count of\n",
    "    # features desired. The |input_crime_data| is the input DataFrame. The |actual_crime|\n",
    "    # is the desired output.\n",
    "    def dump_top_features(self, feature_count):\n",
    "        self.classifier.fit(self.high_crime_input, self.high_crime_output)\n",
    "        top_feature_list = CrimePredictorBase.get_top_features(self, feature_count, \n",
    "                                                               self.classifier.coef_, SVMCrimePredictor.MaxHeapFeatures)\n",
    "        print(\"\\n\\nTop feature list for RidgeCV high crime rate is\")\n",
    "    \n",
    "        for feature in top_feature_list:\n",
    "            print(feature)\n",
    "\n",
    "        self.classifier.fit(self.low_crime_input, self.low_crime_output)\n",
    "        top_feature_list = CrimePredictorBase.get_top_features(self, feature_count, \n",
    "                                                               self.classifier.coef_, SVMCrimePredictor.MaxHeapFeatures)\n",
    "        print(\"\\n\\nTop feature list for RidgeCV low crime rate is\")\n",
    "    \n",
    "        for feature in top_feature_list:\n",
    "            print(feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** RidgeRegression tests ******\n",
      "\n",
      "Read:  1993  records\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n****** RidgeRegression tests ******\\n\")\n",
    "\n",
    "alphas = np.array([10, 1, 0.1, 0.01, 0.001])\n",
    "ridge_regression_crime_predictor = RidgeRegressionCrimePredictor(\"communities-crime-clean.csv\"\n",
    "                                                                 , alphas, True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3b i. What is the estimated MSE of the model under 10-fold CV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeCV crossvalidation score for  10  folds is\n",
      "Cross Validation scores for  10 folds\n",
      "MSE is  0.0197950213482\n"
     ]
    }
   ],
   "source": [
    "ridge_regression_crime_predictor.cross_val_score(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3b ii. What is the MSE on the training set (train on all the data then test on it all)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RidgeCV on whole data set\n",
      "MSE is 0.0167635291552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.17213058,  0.30878933,  0.55261082, ...,  0.10295043,\n",
       "        0.16031921,  0.16959889])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_regression_crime_predictor.run_classifier_on_whole_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3b iii. What is the best alpha?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha is  1.0\n"
     ]
    }
   ],
   "source": [
    "ridge_regression_crime_predictor.get_best_alpha()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3b iv: What does this say about the amount of overfitting in linear regression for this problem?\n",
    "Cross validation Mean square error for Linear regression is 0.0200939693044\n",
    "Mean square error on whole data set is 0.0165167748803\n",
    "\n",
    "Cross validation Mean square error for Ridge regression is 0.0197950213482\n",
    "Mean square error on whole data set is 0.0167635291552\n",
    "\n",
    "The cross validation scores are a better predictor of how the classifier will\n",
    "perform against real world data. At least for this dataset, the MSE for Linear regression\n",
    "is higher than Ridge regression, which indicates that there is some amount of overfitting\n",
    "in the Linear regression model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** LinearRegression second order polynomial features tests ******\n",
      "\n",
      "Read:  1993  records\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n****** LinearRegression second order polynomial features tests ******\\n\")\n",
    "\n",
    "linear_regression_crime_predictor = LinearRegressionCrimePredictor(\"communities-crime-clean.csv\",\n",
    "                                                                   True, 2, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3c i. What is the estimated MSE of the model under 10-fold CV?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression crossvalidation score for  10  folds is\n",
      "Cross Validation scores for  10 folds\n",
      "MSE is  0.129898157392\n"
     ]
    }
   ],
   "source": [
    "linear_regression_crime_predictor.cross_val_score(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3c ii. What is the MSE on the training set (train on all the data then test on it all)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LinearRegresion on whole data set\n",
      "MSE is 1.39689621363e-28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.06,  0.14,  1.  , ...,  0.12,  0.27,  0.06])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression_crime_predictor.run_classifier_on_whole_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3c iii. Does this mean the quadratic model is better than the linear model for this problem?\n",
    "Answer:\n",
    "Cross validation Mean square error for the quadratic second order polynomial test is \n",
    "0.129898157392\n",
    "It is  even lower when run on the whole dataset. 1.39689621363e-28\n",
    "This does not necessarily mean the second order polynomial is better. While the MSE\n",
    "for cross validation is lower for the second order polynomial, these models are also\n",
    "known to overfit the data leading to poor performance when exposed to real world data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dirty Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** DecisionTreeClassifier tests on full dataset ******\n",
      "\n",
      "Read:  1994  records\n",
      "\n",
      "\n",
      "Top feature list for DecisionTreeClassifier is\n",
      "PctKids2Par\n",
      "racePctWhite\n",
      "pctWInvInc\n",
      "racePctHisp\n",
      "PctWOFullPlumb\n",
      "HousVacant\n",
      "MalePctNevMarr\n",
      "pctWRetire\n",
      "perCapInc\n",
      "AsianPerCap\n",
      "\n",
      "****** End of DecisionTreeClassifier tests ******\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n****** DecisionTreeClassifier tests on full dataset ******\\n\")\n",
    "\n",
    "decision_tree_crime_predictor = DecisionTreeCrimePredictor(\"communities-crime-full.csv\", False)\n",
    "decision_tree_crime_predictor.dump_top_features(10)\n",
    "\n",
    "print(\"\\n****** End of DecisionTreeClassifier tests ******\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classification on whole data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DecisionTreeClassifier on whole data set\n",
      "Confusion matrix [[ 679    0]\n",
      " [   0 1315]]\n",
      "Accuracy 1.0\n",
      "Precision 1.0\n",
      "Recall 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_crime_predictor.run_classifier_on_whole_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classification on Train-Test split with 25% for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DecisionTreeClassifier with train test split:  0.25\n",
      "Confusion matrix [[123  61]\n",
      " [ 40 275]]\n",
      "Accuracy 0.797595190381\n",
      "Precision 0.818452380952\n",
      "Recall 0.873015873016\n"
     ]
    }
   ],
   "source": [
    "decision_tree_crime_predictor.run_classifier_with_train_test_split(0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV results for full (non-clean) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree crossvalidation score for  10  folds is\n",
      "Cross Validation scores for  10 folds\n",
      "Accuracy:  0.775355692604\n",
      "Precision:  0.83444175454\n",
      "Recall:  0.823577376822\n"
     ]
    }
   ],
   "source": [
    "decision_tree_crime_predictor.cross_val_score(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4a. Are the CV results better or worse? What does this say about the effect of missing values?\n",
    "Answer:\n",
    "The Cross validation results on the full dataset were better than the clean dataset.\n",
    "This indicates that the missing values had a lot of effect on the performance of the classifier.\n",
    "Additionally it also means that the method of imputing the missing values based on the average\n",
    "may not be desirable. This is because averages are generally sensitive to outliers. Perhaps\n",
    "the median may be a better appoach here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Teams "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-linear SVM with RBF kernel- clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** Nonlinear SVM with RBF kernel tests ******\n",
      "\n",
      "Read:  1993  records\n",
      "Running  rbf on whole data set\n",
      "Confusion matrix [[ 502  177]\n",
      " [ 160 1154]]\n",
      "Accuracy 0.830908178625\n",
      "Precision 0.86701728024\n",
      "Recall 0.878234398782\n",
      "SVM kernel  rbf  crossvalidation score for  10  folds is\n",
      "Cross Validation scores for  10 folds\n",
      "Accuracy:  0.81072493782\n",
      "Precision:  0.854344127903\n",
      "Recall:  0.866568355309\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n****** Nonlinear SVM with RBF kernel tests ******\\n\")\n",
    "\n",
    "svm_rbf_crime_predictor = SVMCrimePredictor(\"communities-crime-clean.csv\", \"rbf\", True, True)\n",
    "\n",
    "svm_rbf_crime_predictor.run_classifier_on_whole_dataset()\n",
    "svm_rbf_crime_predictor.cross_val_score(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-linear SVM with RBF kernel- full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** Nonlinear SVM with RBF kernel tests on full dataset ******\n",
      "\n",
      "Read:  1994  records\n",
      "Running  rbf on whole data set\n",
      "Confusion matrix [[ 462  217]\n",
      " [   0 1315]]\n",
      "Accuracy 0.891173520562\n",
      "Precision 0.858355091384\n",
      "Recall 1.0\n",
      "SVM kernel  rbf  crossvalidation score for  10  folds is\n",
      "Cross Validation scores for  10 folds\n",
      "Accuracy:  0.69862915588\n",
      "Precision:  0.800246316994\n",
      "Recall:  0.72323617858\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n****** Nonlinear SVM with RBF kernel tests on full dataset ******\\n\")\n",
    "\n",
    "svm_rbf_crime_predictor = SVMCrimePredictor(\"communities-crime-full.csv\", \"rbf\", True, False)\n",
    "svm_rbf_crime_predictor.run_classifier_on_whole_dataset()\n",
    "svm_rbf_crime_predictor.cross_val_score(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisticRegressionCrimePredictor(CrimePredictorBase):\n",
    "    def __init__(self, file_name, clean):\n",
    "        CrimePredictorBase.__init__(self, file_name, clean)\n",
    "        self.classifier = LogisticRegression()\n",
    "        \n",
    "    def cross_val_score(self, folds):\n",
    "        print(\"Logistic regression crossvalidation score for \", folds, \" folds is\")\n",
    "        CrimePredictorBase.cross_val_score(self, self.classifier, folds)\n",
    "        \n",
    "    # Gets the top features used for prediction. The |feature_count| is the count of\n",
    "    # features desired. The |input_crime_data| is the input DataFrame. The |actual_crime|\n",
    "    # is the desired output.\n",
    "    def dump_top_features(self, feature_count):\n",
    "        actual_crime = np.where(self.actual_crime_class == \"true\", 1, 0)\n",
    "        self.classifier.fit(self.input_crime_data, actual_crime)\n",
    "        top_feature_list = CrimePredictorBase.get_top_features(self, feature_count, self.classifier.coef_[0], SVMCrimePredictor.MaxHeapFeatures)\n",
    "        print(\"\\n\\nTop feature list for LogisticRegression are\")\n",
    "    \n",
    "        for feature in top_feature_list:\n",
    "            print(feature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression for clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** LogisticRegression tests ******\n",
      "\n",
      "Read:  1993  records\n",
      "\n",
      "\n",
      "Top feature list for LogisticRegression are\n",
      "racepctblack\n",
      "pctWInvInc\n",
      "racePctWhite\n",
      "racePctHisp\n",
      "MalePctDivorce\n",
      "PctKids2Par\n",
      "PersPerRentOccHous\n",
      "PctIlleg\n",
      "HousVacant\n",
      "agePct65up\n",
      "Logistic regression crossvalidation score for  10  folds is\n",
      "Cross Validation scores for  10 folds\n",
      "Accuracy:  0.810742754175\n",
      "Precision:  0.863707911957\n",
      "Recall:  0.854354614851\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n****** LogisticRegression tests ******\\n\")\n",
    "logistic_regression = LogisticRegressionCrimePredictor(\"communities-crime-clean.csv\", True)\n",
    "\n",
    "logistic_regression.dump_top_features(10)\n",
    "\n",
    "logistic_regression.cross_val_score(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression with full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** LogisticRegression tests on full dataset ******\n",
      "\n",
      "Read:  1994  records\n",
      "\n",
      "\n",
      "Top feature list for LogisticRegression are\n",
      "TotalPctDiv\n",
      "FemalePctDiv\n",
      "PctIlleg\n",
      "MalePctDivorce\n",
      "pctWPubAsst\n",
      "racepctblack\n",
      "PctHousNoPhone\n",
      "PctKids2Par\n",
      "racePctWhite\n",
      "PctPopUnderPov\n",
      "Logistic regression crossvalidation score for  10  folds is\n",
      "Cross Validation scores for  10 folds\n",
      "Accuracy:  0.73917222476\n",
      "Precision:  0.7515699745\n",
      "Recall:  0.940718251214\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n****** LogisticRegression tests on full dataset ******\\n\")\n",
    "logistic_regression = LogisticRegressionCrimePredictor(\"communities-crime-full.csv\", False)\n",
    "\n",
    "logistic_regression.dump_top_features(10)\n",
    "\n",
    "logistic_regression.cross_val_score(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5 2. What method gives the best results.\n",
    "Answer: \n",
    "Results from the SVM rbf kernel are as below for cross validation.\n",
    "Accuracy:  0.81072493782\n",
    "Precision:  0.854344127903\n",
    "Recall:  0.866568355309\n",
    "\n",
    "We tried logistic regression as second option\n",
    "Accuracy:  0.810742754175\n",
    "Precision:  0.863707911957\n",
    "Recall:  0.854354614851\n",
    "\n",
    "The SVM rbf kernel and logistic regression classifiers both report higher\n",
    "accuracy/precision/recall when compare with the other classifiers used above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5 3. What feature(s) seem to be most consistently predictive of high crime rates? How reliable is this conclusion?\n",
    "Answer:\n",
    "\n",
    "We got the top 10 features for Logistic regression:\n",
    "racepctblack,\n",
    "pctWInvInc,\n",
    "racePctWhite,\n",
    "racePctHisp,\n",
    "MalePctDivorce,\n",
    "PctKids2Par,\n",
    "PersPerRentOccHouse,\n",
    "PctIlleg,\n",
    "ousVacant,\n",
    "agePct65up\n",
    "\n",
    "Comparing them with the top features for Decision tree, Gaussian Naive Bayes, Linear SVM,\n",
    "it looks like the top features consistently predictive of high crime rates are as below:\n",
    "1. racepctblack\n",
    "2. racepctWhite.\n",
    "3. racepctHisp\n",
    "4. PctKids2Par\n",
    "5. PctIlleg\n",
    "6. MalePctDivorce.\n",
    "\n",
    "Almost all the classifiers used report these features in their top feature list. Based on\n",
    "the description of these features, it is very safe to suggest that values of these features\n",
    "are a very good predictor of crime rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.Extra Credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM regression with RBF kernel on clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** SVM regression with RBF kernel tests ******\n",
      "\n",
      "Read:  1993  records\n",
      "SVM kernel  rbf  crossvalidation score for  10  folds is\n",
      "Cross Validation scores for  10 folds\n",
      "MSE is  0.0198258400241\n",
      "Running  rbf on whole data set\n",
      "MSE is 0.0172768123349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.13682078,  0.2706237 ,  0.54588162, ...,  0.11856709,\n",
       "        0.16033124,  0.15946845])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n****** SVM regression with RBF kernel tests ******\\n\")\n",
    "\n",
    "svm_rbf_regresion = SVMCrimePredictor(\"communities-crime-clean.csv\", \"rbf\", False, True)\n",
    "svm_rbf_regresion.cross_val_score(10)\n",
    "svm_rbf_regresion.run_classifier_on_whole_dataset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM regression with RBF kernel on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** SVM regression with RBF kernel tests on full dataset ******\n",
      "\n",
      "Read:  1994  records\n",
      "SVM kernel  rbf  crossvalidation score for  10  folds is\n",
      "Cross Validation scores for  10 folds\n",
      "MSE is  0.031435408819\n",
      "Running  rbf on whole data set\n",
      "MSE is 0.0158430959027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.20832106,  0.30741923,  0.35682014, ...,  0.21330389,\n",
       "        0.21330389,  0.48060249])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n****** SVM regression with RBF kernel tests on full dataset ******\\n\")\n",
    "\n",
    "svm_rbf_regresion = SVMCrimePredictor(\"communities-crime-full.csv\", \"rbf\", False, False)\n",
    "svm_rbf_regresion.cross_val_score(10)\n",
    "svm_rbf_regresion.run_classifier_on_whole_dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class KNNCrimePredictor(CrimePredictorBase):\n",
    "    def __init__(self, file_name, clean):\n",
    "        CrimePredictorBase.__init__(self, file_name, clean)\n",
    "        self.classifier = KNeighborsClassifier(n_neighbors= 5, metric= 'minkowski', p=2)\n",
    "        \n",
    "    def cross_val_score(self, folds):\n",
    "        print(\"KNN crossvalidation score for \", folds, \" folds is\")\n",
    "        CrimePredictorBase.cross_val_score(self, self.classifier, folds)\n",
    "\n",
    "    def run_classifier_on_whole_dataset(self):\n",
    "        print(\"Running KNN on whole data set\")\n",
    "        return CrimePredictorBase.run_classifier_on_whole_dataset(self, self.classifier)\n",
    "        \n",
    "    def run_classifier_with_train_test_split(self, size):\n",
    "        print(\"Running KNN with train test split: \", size)\n",
    "        return CrimePredictorBase.run_classifier_with_train_test_split(self, self.classifier, size)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** KNN tests ******\n",
      "\n",
      "Read:  1993  records\n",
      "Running KNN on whole data set\n",
      "Confusion matrix [[ 529  150]\n",
      " [ 110 1204]]\n",
      "Accuracy 0.869543401907\n",
      "Precision 0.889217134417\n",
      "Recall 0.916286149163\n",
      "KNN crossvalidation score for  10  folds is\n",
      "Cross Validation scores for  10 folds\n",
      "Accuracy:  0.756549033044\n",
      "Precision:  0.809046141881\n",
      "Recall:  0.828492944714\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n****** KNN tests ******\\n\")\n",
    "KNN_crime_predictor = KNNCrimePredictor(\"communities-crime-clean.csv\", True)\n",
    "KNN_crime_predictor.run_classifier_on_whole_dataset()\n",
    "KNN_crime_predictor.cross_val_score(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RandomForestCrimePredictor(CrimePredictorBase):\n",
    "    def __init__(self, file_name, clean):\n",
    "        CrimePredictorBase.__init__(self, file_name, clean)\n",
    "        self.classifier = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)\n",
    "        \n",
    "    def cross_val_score(self, folds):\n",
    "        print(\"Random Forest crossvalidation score for \", folds, \" folds is\")\n",
    "        CrimePredictorBase.cross_val_score(self, self.classifier, folds)\n",
    "\n",
    "    def run_classifier_on_whole_dataset(self):\n",
    "        print(\"Running RandomForestClassifier on whole data set\")\n",
    "        return CrimePredictorBase.run_classifier_on_whole_dataset(self, self.classifier)\n",
    "        \n",
    "    def run_classifier_with_train_test_split(self, size):\n",
    "        print(\"Running Random Forest with train test split: \", size)\n",
    "        return CrimePredictorBase.run_classifier_with_train_test_split(self, self.classifier, size)\n",
    "\n",
    "    def dump_top_features(self, feature_count):\n",
    "        self.classifier.fit(self.input_crime_data, self.actual_crime_class)\n",
    "        top_feature_list = CrimePredictorBase.get_top_features(self, feature_count, self.classifier.feature_importances_, SVMCrimePredictor.MaxHeapFeatures)\n",
    "        print(\"\\n\\nTop feature list for RandomForestClassifier is\")\n",
    "    \n",
    "        for feature in top_feature_list:\n",
    "            print(feature)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** RandomForestClassifier tests ******\n",
      "\n",
      "Read:  1993  records\n",
      "Running RandomForestClassifier on whole data set\n",
      "Confusion matrix [[ 678    1]\n",
      " [  12 1302]]\n",
      "Accuracy 0.993477170095\n",
      "Precision 0.999232540292\n",
      "Recall 0.990867579909\n",
      "Random Forest crossvalidation score for  10  folds is\n",
      "Cross Validation scores for  10 folds\n",
      "Accuracy:  0.798205065733\n",
      "Precision:  0.861442892349\n",
      "Recall:  0.831534813787\n",
      "\n",
      "\n",
      "Top feature list for RandomForestClassifier is\n",
      "PctFam2Par\n",
      "PctKids2Par\n",
      "FemalePctDiv\n",
      "racePctWhite\n",
      "PctYoungKids2Par\n",
      "PctPopUnderPov\n",
      "PctIlleg\n",
      "pctWInvInc\n",
      "racepctblack\n",
      "NumUnderPov\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n****** RandomForestClassifier tests ******\\n\")\n",
    "RFC_crime_predictor = RandomForestCrimePredictor(\"communities-crime-clean.csv\", True)\n",
    "RFC_crime_predictor.run_classifier_on_whole_dataset()\n",
    "RFC_crime_predictor.cross_val_score(10)\n",
    "RFC_crime_predictor.dump_top_features(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 6b i. What method gives the best results?\n",
    "We tried SVM regression with RBF kernel, K nearest neighbor and Random forest classifier.\n",
    "\n",
    "Cross validation MSE for SVM regression is 0.0198258400241\n",
    "\n",
    "Cross validation scores for K Nearest neighbor\n",
    "Accuracy:  0.756549033044\n",
    "Precision:  0.809046141881\n",
    "Recall:  0.828492944714\n",
    "\n",
    "Cross validation scores for RandomForestClassifier:\n",
    "Accuracy:  0.798205065733\n",
    "Precision:  0.861442892349\n",
    "Recall:  0.831534813787\n",
    "\n",
    "The SVM regression with RBF kernel gives similar results as Ridge regression. But using a non\n",
    "linear kernel could potentially lead to overfitting. \n",
    "\n",
    "It looks like RandomForestClassifier gives the best results in the above list.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6b ii. What features seem to be consistently predictive of high crime rates? How reliable is this conclusion?\n",
    "Answer:\n",
    "The top feature list reported by RandomForestClassifier is as below:\n",
    "PctFam2Par\n",
    "PctKids2Par\n",
    "FemalePctDiv\n",
    "racePctWhite\n",
    "PctYoungKids2Par\n",
    "PctPopUnderPov\n",
    "PctIlleg\n",
    "pctWInvInc\n",
    "racepctblack\n",
    "NumUnderPov\n",
    "\n",
    "Comparing these with the top features reported by Decision tree, LinearSVM, Gaussian NB, LogisticRegression, it looks like the top features consistently predictive of high crime rates are as below:\n",
    "1. PctKids2Par\n",
    "2. racePctWhite.\n",
    "3. PctIlleg\n",
    "4. racepctBlack\n",
    "\n",
    "This is purely based on an intersection between the top features across all classifiers. These are common across all the classifiers we tried and hence are reliable predictors of crime rates.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
